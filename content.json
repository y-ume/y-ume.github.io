{"meta":{"title":"y-ume","subtitle":null,"description":null,"author":"y-ume","url":"http://y-ume.com"},"pages":[{"title":"","date":"2025-12-09T13:11:13.089Z","updated":"2025-12-06T08:46:51.374Z","comments":true,"path":"404.html","permalink":"http://y-ume.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2025-12-09T13:11:13.089Z","updated":"2025-12-06T08:46:51.374Z","comments":true,"path":"categories/index.html","permalink":"http://y-ume.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2025-12-09T13:11:13.086Z","updated":"2025-12-06T08:46:51.372Z","comments":true,"path":"about/index.html","permalink":"http://y-ume.com/about/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2025-12-09T13:11:13.089Z","updated":"2025-12-06T08:46:51.372Z","comments":true,"path":"tags/index.html","permalink":"http://y-ume.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Google Agent 白皮书 1/5 - 认识Agent","slug":"Google-Agent-白皮书-1-5-认识Agent","date":"2025-12-25T23:29:08.000Z","updated":"2025-12-25T23:34:50.797Z","comments":true,"path":"2025/12/26/Google-Agent-白皮书-1-5-认识Agent/","permalink":"http://y-ume.com/2025/12/26/Google-Agent-%E7%99%BD%E7%9A%AE%E4%B9%A6-1-5-%E8%AE%A4%E8%AF%86Agent/","excerpt":"","text":"写在前面在Google Gemini 3发布前一周Google发了一系列关于Agent的白皮书，总共5本： Introduction to Agents Agent Tools &amp; Interoperability with MCP Agent Quality Context Engineering: Sessions, Memory Prototype to Production Gemini 3的出现加速了AI竞争结局的收敛，其光芒掩盖了这几本不受关注的白皮书，或者说白皮书原先也不会有什么光芒。有幸通过微信公众号捕捉到了这几篇白皮书的信息。阅读了第一篇《Introduction to Agents》和其他几篇的内容定位后，准备做个人解读。一方面因为当今信息流已充斥着各种AI工作流形成的产物，希望通过跳跃式且略有拗口的人的风格来介绍这几篇白皮书；另一方面希望通过文字输出来提升个人对Agent的理解。愿这些内容为你带来帮助，无论是当下还是未来。以下是Gemini 3 Flash对《为什么Google在发布Gemini 3前1周发布了5篇Agent的白皮书？》的回答。(Gemini can make mistakes, so double-check it) 文中的斜体代表非原文但容易被理解为原文的内容。 正文文中最上方是用超大引用块突出的文字： Agents are the natural evolution of Language Models, made useful in software. 自然演进这个用词很有趣，让我联想到微软CEO Satya提到的「好工具来自人类认知的自然形式」。 从预测性AI到自主Agent提到范式转变（paradigm shift）。GPT前AI聚焦点问题的预测，GPT后AI聚焦用一个模型实现相同输入形态的预测（语言、视觉、听觉），再往后开始用多模态模型完成不同形式输入和输出的预测。 而我们正在见证一种范式转变，从仅仅能预测或创建内容的人工智能，转向一类能够自主解决问题和执行任务的新型软件。 AI Agents介绍AI Agent被定义为了四个部分： 模型（大脑）: 通过核心语言模型或基础模型处理信息、评估选择和做出决策。 这边很有趣的一个点是先用的是core language model，而在后面提到模型类型的时候才提到了multimodal（多模态）。Gemini 3刚出来我的直觉是「这次Google的优势在于多模型技术」。而这边强调了language的核心，更偏向于人脑的理性思考媒介，其他模态需要更好地服务于语言模态。 工具（双手）：通过工具将智能体的推理与外部世界连接起来，使其能执行文本生成之外的操作。 编排层（神经系统）：管理智能体操作循环的主导流程，负责规划、记忆和推理策略执行。 部署（身体和腿）：将智能体和交互页面部署到可靠的服务器和用户终端。 这边将智能体比作了人，但有点勉强。人的工具也可以包括身体和腿；编排层和模型合在一起更像是人的大脑，神经系统更像是模型调用工具的方式；部署更像是基因和社会。 大白话讲如何构建AI Agent： 挑选一个合适的语言模型（一个思考能力能满足任务的模型） 挑选一组合适且可以调用的工具（完成任务的必要工具） 编排流程，循环进行规划、记忆和推理（循环控制语言模型完成子任务） 调试Agent直到正常运行（监控过程和日志，优化以上三点） 当Agent被精确配置，拥有清晰的指令、可靠的工具、上下文的记忆、不错的用户界面、规划与解决问题的能力以及通用的世界知识时，它就超越了单纯的「工作流自动化」的概念，而是作为一个团队中一个高效、适应性极强且能力卓越的新成员。这里新成员的定调颇有代指工具人的意味。确实目前已经看到可预计完成的任务已经可以交给智能体来全盘处理。 上下文可能包括：系统指令、用户输入、会话历史、长期记忆、来自权威来源的基础知识、可用工具以及已调用工具的结果。 代理问题解决过程我们将AI Agent定义为一个完整的、以目标为导向的应用程序，它整合了推理模型、可执行工具和一个主导的编排层。简而言之，就是「与工具形成循环以实现目标的语言模型」。按照MBTI来看，AI Agent像是ENTJ：以目标为导向、整合资源、全局指挥。 上图是Agent的五个步骤，包括： 获取任务（容易理解） 扫描场景（程序初始化，上班初始化） 深入思考（核心步骤，思考如何制定完成目标的分解步骤） 采取行动（根据步骤调用接口、运行代码、查找数据） 观察与迭代（通过动作结果的观察更新记忆回到第3步）这里的3-4-5的流程和强化学习的结构类似，「决策-执行-环境改变」循环 文中举了一个例子（重点描述了3-4-5的循环）： 用户问道：“我的12345号订单在哪里？” 深入思考 “用户想知道配送状态。要给出完整的答案，我需要一个多步骤计划： 确认：我必须首先在我们的内部数据库中找到该订单，以确认其存在并获取其详细信息。 追踪：根据这些细节，我需要提取运输承运商的追踪号码。然后，我会查询外部承运商的API以获取实时状态。 报告：最后，我必须将收集到的信息整合为一个清晰、有用的回复给用户。 采取行动「确认」，调用「find_order(“12345”)」，观察到「追踪号码“ZYX987”」 思考「已完成第一步，进入第二步」，调用「get_shipping_status（”ZYX987”）」，观察到「正在配送中」 思考「已完成第二步，进行第三步」，生成报告「您的订单#12345状态为‘正在配送中’！」。最后的一次步骤可以认为是调用了语言模型来生成报告，观察到报告后回到思考步骤并确认已完成目标 Agent分级到了喜闻乐见的「L几」定义章节了。每一个级别都是在上个级别的基础上做了能力补充。定义还是很容易理解的，有一种「从初代GPT3走向MOSS」的感觉。 L0：核心推理系统即语言模型本身，仅基于庞大的预训练知识进行响应，不借助任何工具、记忆，也不与实时环境进行交互。GPT3刚出的时候位于L0级别，语言模型有训练截止日期，无法获知训练完成后的任何真实数据 L1：互联问题解决者在L0的基础上，引擎可以通过连接并利用外部工具，不再局限于静态的、预训练的知识。这个级别可以完整的完成Agent的五个步骤。为什么从L0而不是L1定义，一方面L0的出现是基石，另一方面L1才开始是完整的Agent当前具备联网搜索功能的AI可以认为位于L1级别，无论是通过RAG还是实时API实现 L2：策略问题解决者在L1的基础上，L2可以从执行简单任务转变为策略性地规划和解决复杂的问题。用简单到复杂的定义来区分L1和L2有点模糊。我当前用3-4-5是否循环来区分L1和L2。L2强调了循环的重要性，即如何更好地利用记忆（当前主流是上下文）。当前的自动化编程软件可以认为位于L2级别 L3：协作式多智能体系统在L2的基础上，范式进一步发生转变。这个节点下智能体开始以团队形式协同工作，可以类比一个项目下不同成员的分工。这个级别可以认为是L2并行的版本当前部分自动化编程软件已具备这个能力，但费用高（GPU消耗线性增加） L4：自我进化系统最高级L4代表Agent可以识别自身能力的不足，并动态创建工具甚至新智能体来弥补这些不足。当前还没有看到公开的L4 Agent，但目前来看写代码和编译的动作都属于L3下可以解决的。L4需要解决如何识别不足和形成工具设计规格。去查了一下流浪地球2的台词：这是550C，目前最先进的自感知、自适应、自组织、可重塑编译计算核心，在于硬件连接以后可以实时生成低层操作系统，自行组织发动机建设。不夸张地说，如果量子计算机+L4，我们就会步入科幻。 Agent核心架构：模型、工具与编排以下内容就是开始教你搭建Agent了，详细的攻略可以去看看原白皮书，我们很快过一遍~ 模型选型需要考虑智能体的认知能力、运营成本和速度，即质量、速度和价格。可以考虑用混合模型来做，不同的模型负责不同的语言任务，达到最优的速度和成本。语音和图像先转为文本，再通过语言模型进行推理。模型的帕累托前沿还在提升，需要从架构层考虑快速替换模型。 工具一个强大的工具接口包含三部分循环：定义工具的功能、调用工具以及观察结果。工具的三循环对应3-4-5循环白皮书《Agent Tools &amp; Interoperability with Model Context Protocol (MCP)》会专门介绍工具。 检索信息检索增强生成（RAG）就类似从图书馆借阅书籍。对于结构化数据，可通过自然语言转SQL的方式查找准确的信息。 执行操作可以将现有的API和代码函数包装成工具。需要控制在安全的沙箱环境中。可以支持人机交互，即中断工作流或介入流程。 函数调用像函数调用一样使用工具，需要清晰的指令、安全的连接以及编排。和编程中基类逻辑一致，每个工具都可以抽象为一个类 编排层考虑如何设计3-4-5循环 核心设计选择确定Agent的自主程度，需要确保循环可以确定性的、可预测地完成任务。考虑实现方法是否采用代码构建。代码框架Google推了自己的工具包，无代码平台搜了一下看到了阿里的AgentRun。阿里不愧是我最看好的国内AI公司（哈哈哈） 结合领域知识和角色设计指令通过提示词让智能体有人设、有限制、有期望输出。Agent的课题就是如何用自然语言来编程 用上下文增强短期记忆是Agent活跃的暂存区，用于保存对话的历史并跟踪循环的「动作-观察」对。长期记忆通过RAG系统实现。白皮书《Context Engineering: Sessions &amp; Memory》会专门介绍智能体记忆。 多智能体系统与设计模式将一个大型任务分割为离散的子任务，每个子任务分配各一个专门的、专业的AI Agent处理。对于非线性任务，会出现一个管理者的角色，类比项目经理分配任务和资源。对于线性任务，顺序模式即可。迭代优化任务会出现一个评估Agent和一个提示词Agent，来迭代结果。 部署Google推荐了Vertex AI Agent Engine。以前能部署的基础设施依然可以使用。 Agent运维测试Agent运行符合预期，不能用传统的确定性结果测试方法，因为Agent的结果有不确定性。因此我们用语言模型来评估质量，引出了Agent Ops（智能体运维）的概念。白皮书《Agent Quality》会介绍如何评估智能体质量。 衡量重要的事物：像A&#x2F;B实验一样衡量成功用KPI的方式定义Agent的价值，分解为目标完成率、用户满意度评分、任务延迟、交互运营成本等。 质量通过语言模型评估基于语言模型通过一组优质提示数据集进行自动化评估，提供一种一致的指令衡量标准。创建数据集非常繁琐，需要从Agent生产和开发交互中抽取样本，并涵盖正负样本，且评估需要有专家审核。 指标驱动开发构建好评估用例，可以开始用榜单PK不同版本的Agent能力了。 使用OpenTelemetry跟踪和调试一个开源的标准化框架，可采集、处理和导出遥测数据（跟踪、指标和日志），以提升软件的可观测性。 珍视人类的反馈反馈即数据，数据即优化。 Agent的互操作性该如何让Agent与人和其他Agent连接。 Agent和人最常见的就是用户界面。人的互动不局限在屏幕和键盘，更先进的Agent开始进入实时模式。人可以通过摄像头和麦克风与Agent交互。 Agent和AgentAgent间必须像Agent和人一样建立连接，核心问题包括「如何发现其他智能体并了解它们做什么」以及「如何进行通信」。Agent2Agent （A2A）协议是为解决这个问题而设计的开放标准。这个协议是L3 Agent的关键。 Agent和钱如果允许Agent进行「购买」，就会涉及到授权、真实性和问责等问题。如果开启真正的智能体经济，我们需要新的标准，让Agent进行安全可靠地交易。Agent Payments Protocol （AP2）是一种开发协议，旨在成为智能体商业的权威语言；x402是一种开放的互联网支付协议，它使用标准的HTTP 402”需要付款“状态码，无需复杂的账号或订阅。想到最近的字节智能手机以及量化交易 使单Agent安全：信任的平衡当你创建了一个AI Agent，你会面对实用性和安全性的权衡。想让他有用，你需要赋予它权力，但每赋予它一份权力都会带来相应的风险。需要从外层进行防护，第一层是在外围定义约束，即每一步会对外界带来影响的接口都需要有相关的控制。第二层是用人工智能来保障其安全，即检查Agent的计划是否有风险。 Agent身份需要授予Agent身份，使其可以通过访问验证并管理Agent的权限。提到一个叫做SPIFFE的标准。 限制访问策略按照Agent的角色授权。 使ADK Agent安全Agent Development Kit需要在Agent运行中防止出现操作越界、提示词注入、越狱尝试、敏感数据泄露等问题。介绍了一种安全框架，可以让你构建出既强大又可信的单一智能体。 单Agent扩展到企业级智能体集群随着系统中Agent的增加，Agent就创建了一个由交互、数据流和潜在安全漏洞组成的新的负责网络。管理这种复杂性需要一个更高阶的治理层。 安全和隐私恶意行为者可通过注入来劫持Agent的指令，约束不佳的Agent可能会泄露敏感数据和专有信息。一个强大的平台需要提供一个纵深策略来降低这些风险。 Agent治理这里用自动驾驶汽车比作Agent。我们需要交通信号灯、车牌和中央控制系统。当今的互联网或者软件开发已经有各类管理方式，但未来需要实现高效的管理 成本和可靠性最终，企业级Agent必须既可靠又有成本效益。企业能赚钱才是关键 Agent如何进行和学习已经上线的Agent会随着时间的推移而跟不上技术的变更。手动更新大量Agent又跟不上变化，一种可扩展性的解决方案是设计能够自主学习和发展的Agent。 Agent如何学习和自我进化学习来源一方面来自于运行时人的体验（人在回路）；另一方面来自于外部信号，包括文件变更、政策变更或其他Agent的批评。进化一方面是上下文增强，即优化记忆方式；另一方面是创建和优化工具； 模拟和Agent Gym是目前的前沿方向。可以在虚拟环境中来构建和运行Agent，即设计出「环境」。这个思路和世界模型相同。 高级Agent的案例介绍了Google Co-Scientist和AlphaEvolve Agent两份工作。 写在最后白皮书最后是结论部分，就不再赘述了。25年可以认为是Agent的元年，AI竞争浪潮和实际使用确实感受到了Agent的落地。拆解白皮书来看，人工智能正在以人的思维方式进化着。但前沿大佬认为AI又进入到了科研的阶段。以我浅显的认知，当前的AI还缺少「想象力」，即如何快速推演变化的能力，因为想象力如同预测，但人的预测是直觉的，当前AI的预测是数据驱动的。也许可以在架构或者计算能力上看到突破。希望下个五年可以看到新的AI范式，让我们见证更多的不可思议。 写于2025-12-23","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"http://y-ume.com/tags/Agent/"}],"keywords":[]}]}